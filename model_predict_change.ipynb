{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Bureau fetched successfully.\n",
      "Data for Bureau_balance fetched successfully.\n",
      "Data for Credit_card_balance fetched successfully.\n",
      "Data for Installments_payments fetched successfully.\n",
      "Data for POS_CASH_balance fetched successfully.\n",
      "Data for Previous_application fetched successfully.\n",
      "Data for Application_train fetched successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a list of table names and their corresponding API endpoints\n",
    "tables = {\n",
    "            \n",
    "        \"Bureau\" : 'http://127.0.0.1:5000/bureau',\n",
    "        \"Bureau_balance\" : 'http://127.0.0.1:5000/bureau_balance',\n",
    "        \"Credit_card_balance\" : 'http://127.0.0.1:5000/credit_card_balance',\n",
    "        \"Installments_payments\" : 'http://127.0.0.1:5000/installments_payments',\n",
    "        \"POS_CASH_balance\" : 'http://127.0.0.1:5000/pOS_CASH_balance',\n",
    "        \"Previous_application\" : 'http://127.0.0.1:5000/previous_application',\n",
    "        \"Application_train\" : 'http://127.0.0.1:5000/application_train'\n",
    "}\n",
    "\n",
    "# Dictionary to store DataFrames for each table\n",
    "dataframes = {}\n",
    "\n",
    "# Make API requests to get data from each table\n",
    "for table_name, endpoint in tables.items():\n",
    "    response = requests.get(endpoint)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convert API response to a DataFrame and store it in the dictionary\n",
    "        dataframes[table_name] = pd.DataFrame(response.json())\n",
    "        print(f\"Data for {table_name} fetched successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch data from {table_name}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AMT_ANNUITY_x  AMT_CREDIT  AMT_GOODS_PRICE  AMT_INCOME_TOTAL  \\\n",
      "0       128313.0   1350000.0        1350000.0          202500.0   \n",
      "1        11101.5    101880.0          90000.0          112500.0   \n",
      "2        11398.5    291915.0         252000.0          315000.0   \n",
      "3        11398.5    291915.0         252000.0          315000.0   \n",
      "4        38551.5   1314117.0        1147500.0          247500.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
      "0                        0.0                         0.0   \n",
      "1                        0.0                         0.0   \n",
      "2                        0.0                         0.0   \n",
      "3                        0.0                         0.0   \n",
      "4                        0.0                         0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
      "0                        0.0                        1.0   \n",
      "1                        0.0                        0.0   \n",
      "2                        0.0                        2.0   \n",
      "3                        0.0                        2.0   \n",
      "4                        0.0                        0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_YEAR  ...  \\\n",
      "0                         0.0                         0.0  ...   \n",
      "1                         0.0                         0.0  ...   \n",
      "2                         0.0                         2.0  ...   \n",
      "3                         0.0                         2.0  ...   \n",
      "4                         0.0                         1.0  ...   \n",
      "\n",
      "   CREDIT_CURRENCY  CREDIT_DAY_OVERDUE CREDIT_TYPE  DAYS_CREDIT  \\\n",
      "0              NaN                 NaN         NaN          NaN   \n",
      "1              NaN                 NaN         NaN          NaN   \n",
      "2              NaN                 NaN         NaN          NaN   \n",
      "3              NaN                 NaN         NaN          NaN   \n",
      "4              NaN                 NaN         NaN          NaN   \n",
      "\n",
      "   DAYS_CREDIT_ENDDATE  DAYS_CREDIT_UPDATE  DAYS_ENDDATE_FACT  SK_ID_BUREAU  \\\n",
      "0                  NaN                 NaN                NaN           NaN   \n",
      "1                  NaN                 NaN                NaN           NaN   \n",
      "2                  NaN                 NaN                NaN           NaN   \n",
      "3                  NaN                 NaN                NaN           NaN   \n",
      "4                  NaN                 NaN                NaN           NaN   \n",
      "\n",
      "   MONTHS_BALANCE_y  STATUS  \n",
      "0               NaN     NaN  \n",
      "1               NaN     NaN  \n",
      "2               NaN     NaN  \n",
      "3               NaN     NaN  \n",
      "4               NaN     NaN  \n",
      "\n",
      "[5 rows x 140 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge tables based on specified keys\n",
    "merged_table = dataframes[\"Application_train\"]\n",
    "\n",
    "# Merge POS_CASH_balance, Installments_payments, Credit_card_balance based on SK_ID_PREV\n",
    "for table_name in [\"POS_CASH_balance\", \"Installments_payments\", \"Credit_card_balance\", \"Previous_application\"]:\n",
    "    if table_name in dataframes:\n",
    "        # Specify suffixes to avoid duplicate column names\n",
    "        merged_table = pd.merge(merged_table, dataframes[table_name], on='SK_ID_CURR', how='left', suffixes=('', f'_{table_name}'))\n",
    "\n",
    "# Merge Bureau and Bureau_balance based on SK_ID_BUREAU\n",
    "if \"Bureau\" in dataframes and \"Bureau_balance\" in dataframes:\n",
    "    bureau_merged = pd.merge(dataframes[\"Bureau\"], dataframes[\"Bureau_balance\"], on='SK_ID_BUREAU', how='left', suffixes=('_bureau', '_bureau_balance'))\n",
    "    merged_table = pd.merge(merged_table, bureau_merged, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Display the final merged table with unique columns\n",
    "unique_columns = merged_table.columns.unique()\n",
    "final_table = merged_table[unique_columns]\n",
    "\n",
    "# Display the final table\n",
    "print(final_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = final_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=final_table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['CODE_GENDER'] = data_df['CODE_GENDER'].replace({'F': 0, 'M': 1})\n",
    "# Changing FLAG_OWN_REALTY AND FLAG_OWN_CAR to 0 and 1 to match model\n",
    "data_df[['FLAG_OWN_REALTY', 'FLAG_OWN_CAR']] = data_df[['FLAG_OWN_REALTY', 'FLAG_OWN_CAR']].replace({'Y': 1, 'N': 0}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[[\"DAYS_ID_PUBLISH\", \"DAYS_BIRTH\", \"DAYS_REGISTRATION\", \"DAYS_LAST_PHONE_CHANGE\",\n",
    "              \"AMT_ANNUITY_x\", \"SK_ID_CURR\", \"DAYS_EMPLOYED\", \"AMT_GOODS_PRICE\", \"AMT_INCOME_TOTAL\",\n",
    "              \"HOUR_APPR_PROCESS_START\", \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"OWN_CAR_AGE\",\n",
    "              \"OBS_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\", \"AMT_PAYMENT\",\n",
    "              \"DAYS_ENTRY_PAYMENT\", \"AMT_INSTALMENT\", \"DAYS_INSTALMENT\", \"NUM_INSTALMENT_NUMBER\",\n",
    "              \"CNT_INSTALMENT_FUTURE\", \"MONTHS_BALANCE_x\", \"CNT_FAM_MEMBERS\", \"CNT_INSTALMENT\",\n",
    "              \"CNT_INSTALMENT_MATURE_CUM\", \"MONTHS_BALANCE_Credit_card_balance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest r2_score: 0.9368523393546543\n",
      "XGBoost r2_score: 0.8890021429199392\n",
      "Lasso Regression r2_score: 0.9871808424096365\n",
      "Neural Network Regression r2_score: 0.9228750723848649\n",
      "AdaBoost r2_score: 0.9300253473569564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 5)\n",
    "y = 3 * X[:, 0] + 2 * X[:, 1] - X[:, 2] + np.random.randn(100) * 0.1  # Sample pricing\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with Random Forest\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for Random Forest\n",
    "rf_rmse = r2_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest r2_score: {rf_rmse}\")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with XGBoost\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for XGBoost\n",
    "xgb_rmse = r2_score(y_test, xgb_predictions)\n",
    "print(f\"XGBoost r2_score: {xgb_rmse}\")\n",
    "\n",
    "# Train Lasso Regression model\n",
    "lasso_model = Lasso(alpha=0.01, random_state=42)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with Lasso Regression\n",
    "lasso_predictions = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for Lasso Regression\n",
    "lasso_rmse = r2_score(y_test, lasso_predictions)\n",
    "print(f\"Lasso Regression r2_score: {lasso_rmse}\")\n",
    "\n",
    "# Train Neural Network Regression model\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with Neural Network Regression\n",
    "nn_predictions = nn_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for Neural Network Regression\n",
    "nn_rmse = r2_score(y_test, nn_predictions)\n",
    "print(f\"Neural Network Regression r2_score: {nn_rmse}\")\n",
    "\n",
    "# Train AdaBoost model\n",
    "adaboost_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with AdaBoost\n",
    "adaboost_predictions = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for AdaBoost\n",
    "adaboost_rmse = r2_score(y_test, adaboost_predictions)\n",
    "print(f\"AdaBoost r2_score: {adaboost_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features\n",
    "X = data_df[[\"DAYS_ID_PUBLISH\", \"DAYS_BIRTH\", \"DAYS_REGISTRATION\", \"DAYS_LAST_PHONE_CHANGE\",\n",
    "              \"AMT_ANNUITY_x\", \"SK_ID_CURR\", \"DAYS_EMPLOYED\", \"AMT_GOODS_PRICE\", \"AMT_INCOME_TOTAL\",\n",
    "              \"HOUR_APPR_PROCESS_START\", \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"OWN_CAR_AGE\",\n",
    "              \"OBS_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\", \"AMT_PAYMENT\",\n",
    "              \"DAYS_ENTRY_PAYMENT\", \"AMT_INSTALMENT\", \"DAYS_INSTALMENT\", \"NUM_INSTALMENT_NUMBER\",\n",
    "              \"CNT_INSTALMENT_FUTURE\", \"MONTHS_BALANCE_x\", \"CNT_FAM_MEMBERS\", \"CNT_INSTALMENT\",\n",
    "              \"CNT_INSTALMENT_MATURE_CUM\", \"MONTHS_BALANCE_Credit_card_balance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "y = data_df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler and transform the data\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Convert categorical columns to dummy variables\n",
    "X_train_dummy = pd.get_dummies(X_train_scaled).astype(int)\n",
    "X_test_dummy = pd.get_dummies(X_test_scaled).astype(int)\n",
    "\n",
    "# Train a RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_dummy, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = rf_model.predict(X_test_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual Values  Predicted Prices\n",
      "0             310671            641387\n",
      "1             450000            517309\n",
      "2             180000            105233\n",
      "3            1185282           1185282\n",
      "4             360000            606637\n",
      "...              ...               ...\n",
      "31578         601470            591765\n",
      "31579        1268743           1163699\n",
      "31580         270000            434464\n",
      "31581        1056447            728437\n",
      "31582         270000            554922\n",
      "\n",
      "[31583 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "result_df = pd.DataFrame({'Actual Values': y_test.astype(int), 'Predicted Prices': predictions.astype(int)}).reset_index(drop=True)\n",
    "\n",
    "# Display the result DataFrame without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming X and y are already defined\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler and transform the data\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Convert categorical columns to dummy variables\n",
    "X_train_dummy = pd.get_dummies(X_train_scaled).astype(int)\n",
    "X_test_dummy = pd.get_dummies(X_test_scaled).astype(int)\n",
    "\n",
    "# Train a Lasso Regression model with increased max_iter\n",
    "lasso_model = Lasso(alpha=0.01, max_iter=10000, random_state=42)  # Adjust alpha and max_iter as needed\n",
    "lasso_model.fit(X_train_dummy, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "lasso_predictions = lasso_model.predict(X_test_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual Values  Predicted Prices\n",
      "0             310671            591637\n",
      "1             450000            576300\n",
      "2             180000            111016\n",
      "3            1185282            986783\n",
      "4             360000            542411\n",
      "...              ...               ...\n",
      "31578         601470            570020\n",
      "31579        1268743           1015932\n",
      "31580         270000            562247\n",
      "31581        1056447            589512\n",
      "31582         270000            572804\n",
      "\n",
      "[31583 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "result_df_lasso = pd.DataFrame({'Actual Values': y_test.astype(int), 'Predicted Prices': lasso_predictions.astype(int)}).reset_index(drop=True)\n",
    "\n",
    "# Display the result DataFrame without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(result_df_lasso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
