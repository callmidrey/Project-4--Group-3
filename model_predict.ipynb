{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from Postgres using APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Bureau fetched successfully.\n",
      "Data for Bureau_balance fetched successfully.\n",
      "Data for Credit_card_balance fetched successfully.\n",
      "Data for Installments_payments fetched successfully.\n",
      "Data for POS_CASH_balance fetched successfully.\n",
      "Data for Previous_application fetched successfully.\n",
      "Data for Application_train fetched successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a list of table names and their corresponding API endpoints\n",
    "tables = {\n",
    "            \n",
    "        \"Bureau\" : 'http://127.0.0.1:5000/bureau',\n",
    "        \"Bureau_balance\" : 'http://127.0.0.1:5000/bureau_balance',\n",
    "        \"Credit_card_balance\" : 'http://127.0.0.1:5000/credit_card_balance',\n",
    "        \"Installments_payments\" : 'http://127.0.0.1:5000/installments_payments',\n",
    "        \"POS_CASH_balance\" : 'http://127.0.0.1:5000/pOS_CASH_balance',\n",
    "        \"Previous_application\" : 'http://127.0.0.1:5000/previous_application',\n",
    "        \"Application_train\" : 'http://127.0.0.1:5000/application_train'\n",
    "}\n",
    "\n",
    "# Dictionary to store DataFrames for each table\n",
    "dataframes = {}\n",
    "\n",
    "# Make API requests to get data from each table\n",
    "for table_name, endpoint in tables.items():\n",
    "    response = requests.get(endpoint)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convert API response to a DataFrame and store it in the dictionary\n",
    "        dataframes[table_name] = pd.DataFrame(response.json())\n",
    "        print(f\"Data for {table_name} fetched successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch data from {table_name}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AMT_ANNUITY_x  AMT_CREDIT  AMT_GOODS_PRICE  AMT_INCOME_TOTAL  \\\n",
      "0       128313.0   1350000.0        1350000.0          202500.0   \n",
      "1        11101.5    101880.0          90000.0          112500.0   \n",
      "2        11398.5    291915.0         252000.0          315000.0   \n",
      "3        11398.5    291915.0         252000.0          315000.0   \n",
      "4        38551.5   1314117.0        1147500.0          247500.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
      "0                        0.0                         0.0   \n",
      "1                        0.0                         0.0   \n",
      "2                        0.0                         0.0   \n",
      "3                        0.0                         0.0   \n",
      "4                        0.0                         0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
      "0                        0.0                        1.0   \n",
      "1                        0.0                        0.0   \n",
      "2                        0.0                        2.0   \n",
      "3                        0.0                        2.0   \n",
      "4                        0.0                        0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_YEAR  ...  \\\n",
      "0                         0.0                         0.0  ...   \n",
      "1                         0.0                         0.0  ...   \n",
      "2                         0.0                         2.0  ...   \n",
      "3                         0.0                         2.0  ...   \n",
      "4                         0.0                         1.0  ...   \n",
      "\n",
      "   CREDIT_CURRENCY  CREDIT_DAY_OVERDUE CREDIT_TYPE  DAYS_CREDIT  \\\n",
      "0              NaN                 NaN         NaN          NaN   \n",
      "1              NaN                 NaN         NaN          NaN   \n",
      "2              NaN                 NaN         NaN          NaN   \n",
      "3              NaN                 NaN         NaN          NaN   \n",
      "4              NaN                 NaN         NaN          NaN   \n",
      "\n",
      "   DAYS_CREDIT_ENDDATE  DAYS_CREDIT_UPDATE  DAYS_ENDDATE_FACT  SK_ID_BUREAU  \\\n",
      "0                  NaN                 NaN                NaN           NaN   \n",
      "1                  NaN                 NaN                NaN           NaN   \n",
      "2                  NaN                 NaN                NaN           NaN   \n",
      "3                  NaN                 NaN                NaN           NaN   \n",
      "4                  NaN                 NaN                NaN           NaN   \n",
      "\n",
      "   MONTHS_BALANCE_y  STATUS  \n",
      "0               NaN     NaN  \n",
      "1               NaN     NaN  \n",
      "2               NaN     NaN  \n",
      "3               NaN     NaN  \n",
      "4               NaN     NaN  \n",
      "\n",
      "[5 rows x 140 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge tables based on specified keys\n",
    "merged_table = dataframes[\"Application_train\"]\n",
    "\n",
    "# Merge POS_CASH_balance, Installments_payments, Credit_card_balance based on SK_ID_PREV\n",
    "for table_name in [\"POS_CASH_balance\", \"Installments_payments\", \"Credit_card_balance\", \"Previous_application\"]:\n",
    "    if table_name in dataframes:\n",
    "        # Specify suffixes to avoid duplicate column names\n",
    "        merged_table = pd.merge(merged_table, dataframes[table_name], on='SK_ID_CURR', how='left', suffixes=('', f'_{table_name}'))\n",
    "\n",
    "# Merge Bureau and Bureau_balance based on SK_ID_BUREAU\n",
    "if \"Bureau\" in dataframes and \"Bureau_balance\" in dataframes:\n",
    "    bureau_merged = pd.merge(dataframes[\"Bureau\"], dataframes[\"Bureau_balance\"], on='SK_ID_BUREAU', how='left', suffixes=('_bureau', '_bureau_balance'))\n",
    "    merged_table = pd.merge(merged_table, bureau_merged, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Display the final merged table with unique columns\n",
    "unique_columns = merged_table.columns.unique()\n",
    "final_table = merged_table[unique_columns]\n",
    "\n",
    "# Display the final table\n",
    "print(final_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop dupliactes\n",
    "data_df = final_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empties with 0\n",
    "data_df=final_table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning 'CODE_GENDER' numerical values\n",
    "data_df['CODE_GENDER'] = data_df['CODE_GENDER'].replace({'F': 0, 'M': 1})\n",
    "# Changing FLAG_OWN_REALTY AND FLAG_OWN_CAR to 0 and 1 to match model\n",
    "data_df[['FLAG_OWN_REALTY', 'FLAG_OWN_CAR']] = data_df[['FLAG_OWN_REALTY', 'FLAG_OWN_CAR']].replace({'Y': 1, 'N': 0}).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = data_df[[\"CNT_FAM_MEMBERS\",\n",
    "                \"OWN_CAR_AGE\",\n",
    "                \"SK_ID_CURR\",\n",
    "                \"AMT_INCOME_TOTAL\",\n",
    "                \"AMT_REQ_CREDIT_BUREAU_YEAR\",\n",
    "                \"OBS_30_CNT_SOCIAL_CIRCLE\",\n",
    "                \"OBS_60_CNT_SOCIAL_CIRCLE\",\n",
    "                \"AMT_ANNUITY_x\",\n",
    "                \"CNT_INSTALMENT_MATURE_CUM\",\n",
    "                \"AMT_PAYMENT\",\n",
    "                \"DAYS_ENTRY_PAYMENT\",\n",
    "                \"AMT_INSTALMENT\",\n",
    "                \"DAYS_INSTALMENT\",\n",
    "                \"NUM_INSTALMENT_NUMBER\",\n",
    "                \"CNT_INSTALMENT_FUTURE\",\n",
    "                \"CNT_INSTALMENT\",\n",
    "                \"MONTHS_BALANCE_Credit_card_balance\",\n",
    "                \"MONTHS_BALANCE_x\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of appropriate machine learning algorithms: Random Forest Regressor, XG Boost, Lasso Regression and Neural Network Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 0.21798580636574888\n",
      "XGBoost RMSE: 0.2898705546802953\n",
      "Lasso Regression RMSE: 0.09850914453283427\n",
      "Neural Network Regression RMSE: 0.24162629190062188\n",
      "AdaBoost RMSE: 0.23015328606206514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 5)\n",
    "y = 3 * X[:, 0] + 2 * X[:, 1] - X[:, 2] + np.random.randn(100) * 0.1  # Sample pricing\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with Random Forest\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for Random Forest\n",
    "rf_rmse = sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with XGBoost\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for XGBoost\n",
    "xgb_rmse = sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "print(f\"XGBoost RMSE: {xgb_rmse}\")\n",
    "\n",
    "# Train Lasso Regression model\n",
    "lasso_model = Lasso(alpha=0.01, random_state=42)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with Lasso Regression\n",
    "lasso_predictions = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for Lasso Regression\n",
    "lasso_rmse = sqrt(mean_squared_error(y_test, lasso_predictions))\n",
    "print(f\"Lasso Regression RMSE: {lasso_rmse}\")\n",
    "\n",
    "# Train Neural Network Regression model\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with Neural Network Regression\n",
    "nn_predictions = nn_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for Neural Network Regression\n",
    "nn_rmse = sqrt(mean_squared_error(y_test, nn_predictions))\n",
    "print(f\"Neural Network Regression RMSE: {nn_rmse}\")\n",
    "\n",
    "# Train AdaBoost model\n",
    "adaboost_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict with AdaBoost\n",
    "adaboost_predictions = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for AdaBoost\n",
    "adaboost_rmse = sqrt(mean_squared_error(y_test, adaboost_predictions))\n",
    "print(f\"AdaBoost RMSE: {adaboost_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = data_df[[\"CNT_FAM_MEMBERS\",\n",
    "                \"OWN_CAR_AGE\",\n",
    "                \"SK_ID_CURR\",\n",
    "                \"AMT_INCOME_TOTAL\",\n",
    "                \"AMT_REQ_CREDIT_BUREAU_YEAR\",\n",
    "                \"OBS_30_CNT_SOCIAL_CIRCLE\",\n",
    "                \"OBS_60_CNT_SOCIAL_CIRCLE\",\n",
    "                \"AMT_ANNUITY_x\",\n",
    "                \"CNT_INSTALMENT_MATURE_CUM\",\n",
    "                \"AMT_PAYMENT\",\n",
    "                \"DAYS_ENTRY_PAYMENT\",\n",
    "                \"AMT_INSTALMENT\",\n",
    "                \"DAYS_INSTALMENT\",\n",
    "                \"NUM_INSTALMENT_NUMBER\",\n",
    "                \"CNT_INSTALMENT_FUTURE\",\n",
    "                \"CNT_INSTALMENT\",\n",
    "                \"MONTHS_BALANCE_Credit_card_balance\",\n",
    "                \"MONTHS_BALANCE_x\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning algorithms: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler and transform the data\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# # Convert categorical columns to dummy variables\n",
    "# X_train_dummy = pd.get_dummies(X_train_scaled).astype(int)\n",
    "# X_test_dummy = pd.get_dummies(X_test_scaled).astype(int)\n",
    "\n",
    "# Train a RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = rf_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Regression RMSE: 283660.1258366763\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for Lasso Regression\n",
    "random_forest_rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RandomForest Regression RMSE: {random_forest_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual Values  Predicted Prices\n",
      "0             753840            679374\n",
      "1             108801            108801\n",
      "2             454500            395196\n",
      "3             454500            513150\n",
      "4             473760            473760\n",
      "...              ...               ...\n",
      "32235        1325475           1325475\n",
      "32236         180000            180000\n",
      "32237         521280            521280\n",
      "32238        1804500           1108366\n",
      "32239         450000            271473\n",
      "\n",
      "[32240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "result_df = pd.DataFrame({'Actual Values': y_test.astype(int), 'Predicted Prices': predictions.astype(int)}).reset_index(drop=True)\n",
    "\n",
    "# Display the result DataFrame without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_predict.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_model, 'model_predict.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Machine learning algorithms: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression RMSE: 310142.213354101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming X and y are already defined\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler and transform the data\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Convert categorical columns to dummy variables\n",
    "X_train_dummy = pd.get_dummies(X_train_scaled).astype(int)\n",
    "X_test_dummy = pd.get_dummies(X_test_scaled).astype(int)\n",
    "\n",
    "# Train a Lasso Regression model with increased max_iter\n",
    "lasso_model = Lasso(alpha=0.01, max_iter=10000, random_state=42)  # Adjust alpha and max_iter as needed\n",
    "lasso_model.fit(X_train_dummy, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "lasso_predictions = lasso_model.predict(X_test_dummy)\n",
    "\n",
    "# Calculate RMSE for Lasso Regression\n",
    "lasso_rmse = sqrt(mean_squared_error(y_test, lasso_predictions))\n",
    "print(f\"Lasso Regression RMSE: {lasso_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual Values  Predicted Prices\n",
      "0             753840            603620\n",
      "1             108801            177878\n",
      "2             454500            545747\n",
      "3             454500            603620\n",
      "4             473760            916890\n",
      "...              ...               ...\n",
      "32235        1325475           1224715\n",
      "32236         180000            279953\n",
      "32237         521280            884616\n",
      "32238        1804500            838127\n",
      "32239         450000            598743\n",
      "\n",
      "[32240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "result_df_lasso = pd.DataFrame({'Actual Values': y_test.astype(int), 'Predicted Prices': lasso_predictions.astype(int)}).reset_index(drop=True)\n",
    "\n",
    "# Display the result DataFrame without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(result_df_lasso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
